{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a25aa434-3ce4-42e1-9015-8e6e1227a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA CLEANING & MERGING FOR PORT AUTHORITY BUS AND PASSENGER\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "tqdm.pandas()  # Enable progress bars for pandas operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "af384d4f-906c-4457-a64b-f47cc3811f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: READ & CLEAN PABT BUS & PASSENGER FILES\n",
    "# ============================================================\n",
    "\n",
    "bus_file = 'All Recorded PABT Bus.txt'\n",
    "pass_file = 'All Recorded PABT Passenger.txt'\n",
    "\n",
    "# --- Read files\n",
    "bus = pd.read_csv(bus_file, sep='\\t')\n",
    "passenger = pd.read_csv(pass_file, sep='\\t')\n",
    "\n",
    "\n",
    "# Function to aggressively clean carrier names for successful merging\n",
    "def clean_carrier(s):\n",
    "    \"\"\"Removes spaces, punctuation, and converts to lowercase to ensure matching.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return ''\n",
    "    s = str(s).lower()\n",
    "    s = s.replace(' ', '')  # Remove spaces (e.g., 'C & J Bus Lines' -> 'C&JBusLines')\n",
    "    s = re.sub(r'[^a-z0-9]', '', s)  # Remove any non-alphanumeric characters (e.g., '-', '_', '&')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "28472058-8f56-4861-a8a7-39d50f80f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strip column names & whitespace\n",
    "bus.columns = bus.columns.str.strip()\n",
    "passenger.columns = passenger.columns.str.strip()\n",
    "\n",
    "# Strip whitespace from all string data columns\n",
    "bus = bus.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "passenger = passenger.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6cf95d59-952f-4593-9ae0-5dea7c28f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize date columns. This step is critical as formats differ:\n",
    "# - BUS FILE dates are DD/MM/YYYY (e.g., '08/02/2021'), requiring dayfirst=True.\n",
    "bus['Start_Date'] = pd.to_datetime(bus['Start_Date'], errors='coerce', dayfirst=True)\n",
    "bus['End_Date'] = pd.to_datetime(bus['End_Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# - PASSENGER FILE dates include a time component (e.g., '2020-12-07 00:00:00.000').\n",
    "#   We convert to datetime, then extract only the date component to align with the bus data.\n",
    "passenger['Start_Date'] = pd.to_datetime(passenger['Start_Date'], errors='coerce').dt.date\n",
    "passenger['End_Date'] = pd.to_datetime(passenger['End_Date'], errors='coerce').dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6c135982-962b-48ea-bcdf-fc7577793031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert Volume to numeric (handle NULLs/empty strings)\n",
    "bus['Volume'] = pd.to_numeric(bus['Volume'].replace(['NULL',''], np.nan), errors='coerce')\n",
    "passenger['Volume'] = pd.to_numeric(passenger['Volume'].replace(['NULL',''], np.nan), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "825820a4-95a6-42c1-93fb-440a38060b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the carrier cleaning function to both dataframes\n",
    "bus['Carrier_clean'] = bus['Carrier'].apply(clean_carrier)\n",
    "passenger['Carrier_clean'] = passenger['Carrier'].apply(clean_carrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2b448da1-09fe-4c63-9109-d1eed28e6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the bus date columns are converted to match the passenger date type (datetime.date)\n",
    "bus['Start_Date'] = pd.to_datetime(bus['Start_Date']).dt.date\n",
    "bus['End_Date'] = pd.to_datetime(bus['End_Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a097a0fa-2f3c-4298-9299-0abc93eb4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: filter out early Dec 2020 from Passenger to match Bus\n",
    "# passenger = passenger[passenger['Start_Date'] >= pd.to_datetime('2021-02-08').date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4bbda3e4-35a0-4143-9e8f-a9657c43a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['Carrier_clean'] = bus['Carrier'].apply(clean_carrier)\n",
    "passenger['Carrier_clean'] = passenger['Carrier'].apply(clean_carrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7d06acc5-b832-40f2-ad31-6f4729f848ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Matched Rows: 2772\n"
     ]
    }
   ],
   "source": [
    "# Count matched & unmatched\n",
    "combined_df = pd.merge(\n",
    "    bus, passenger,\n",
    "    left_on=['Start_Date', 'End_Date', 'Carrier_clean'],\n",
    "    right_on=['Start_Date', 'End_Date', 'Carrier_clean'],\n",
    "    how='outer',\n",
    "    suffixes=('_Bus', '_Passenger'),\n",
    "    indicator=True # Adds '_merge' column to show match status\n",
    ")\n",
    "\n",
    "# Check the success of the merge\n",
    "matched_count = (combined_df['_merge'] == 'both').sum()\n",
    "print(f\"Total Matched Rows: {matched_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "69cfafd5-05fa-40f9-93fc-879f89e1ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After merging bus_df and passenger_df into combined_df\n",
    "combined_df[['Volume_Bus', 'Volume_Passenger']] = combined_df[['Volume_Bus', 'Volume_Passenger']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63aa8b43-23eb-44ae-a0e9-ca5e9116b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Save combined bus-passenger dataset\n",
    "# ===============================\n",
    "\n",
    "# OUTPUT 1: Full Merged Data (All Columns) ---\n",
    "combined_df.to_csv('Raw_Merged_PABT_Bus_Passenger.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8f94d369-6712-4581-b7aa-2385de2bf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final merged data (2,796 records, 4 columns) saved to: data/output/Merged_PABT_Bus_Passenger_For_PowerBI.csv\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT 2: Final Output ---\n",
    "\n",
    "# Define the final requested columns\n",
    "reduced_cols = ['Start_Date', 'End_Date', 'Carrier_clean', 'Volume_Bus', 'Volume_Passenger']\n",
    "\n",
    "# Select only the requested columns from the full combined DataFrame\n",
    "full_ready_to_use = combined_df[reduced_cols]\n",
    "\n",
    "# Save the final, reduced-column file\n",
    "output_file_reduced = 'data/output/Merged_PABT_Bus_Passenger_For_PowerBI.csv'\n",
    "full_ready_to_use.to_csv(output_file_reduced, index=False)\n",
    "\n",
    "print(f\"\\nFinal merged data (2,796 records, 4 columns) saved to: {output_file_reduced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "80f53135-3004-4831-90d9-0d55b36956a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only required if we want to perform predictive analysis on PABT BUS and Passenger dataset.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load merged PABT data\n",
    "df = pd.read_csv(\"data/Output/Merged_PABT_Bus_Passenger_For_PowerBI.csv\", parse_dates=[\"Start_Date\",\"End_Date\"])\n",
    "\n",
    "# 1. Log transform (add 1 to avoid log(0))\n",
    "df[\"log_Volume_Bus\"] = np.log1p(df[\"Volume_Bus\"])\n",
    "df[\"log_Volume_Passenger\"] = np.log1p(df[\"Volume_Passenger\"])\n",
    "\n",
    "# 2. Outlier capping at the 99th percentile\n",
    "for col in [\"Volume_Bus\",\"Volume_Passenger\"]:\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[f\"{col}_capped\"] = np.where(df[col] > upper, upper, df[col])\n",
    "\n",
    "# 3. Zero-inflation flag\n",
    "df[\"bus_zero\"] = (df[\"Volume_Bus\"] == 0).astype(int)\n",
    "df[\"pass_zero\"] = (df[\"Volume_Passenger\"] == 0).astype(int)\n",
    "\n",
    "# 4. Carrier-specific normalization (z-score within each carrier)\n",
    "df[[\"bus_z\",\"pass_z\"]] = df.groupby(\"Carrier_clean\")[[\"Volume_Bus\",\"Volume_Passenger\"]].transform(\n",
    "    lambda x: (x - x.mean())/ x.std(ddof=0)\n",
    ")\n",
    "\n",
    "# 5. (Optional) Zero-inflated Poisson features\n",
    "#    e.g., probability of zero vs non-zero per carrier\n",
    "carrier_zero_rates = df.groupby(\"Carrier_clean\")[\"bus_zero\"].mean().rename(\"bus_zero_rate\")\n",
    "df = df.join(carrier_zero_rates, on=\"Carrier_clean\")\n",
    "\n",
    "# Save prepared dataset\n",
    "df.to_csv(\"data/output/Merged_PABT_Bus_Passenger_For_Predictive.csv\", index=False)\n",
    "\n",
    "# Now df contains:\n",
    "#  - log_Volume_Bus, log_Volume_Passenger\n",
    "#  - Volume_Bus_capped, Volume_Passenger_capped\n",
    "#  - bus_zero, pass_zero flags\n",
    "#  - bus_z, pass_z (carrier-normalized)\n",
    "#  - bus_zero_rate per carrier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfab591-523e-4283-8f91-e73d412fc436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
